{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## HELLO AGAIN CRISSY\n",
    "\n",
    "# Cleaned up most of the code. Looks nicer, much more readable, with clear comments.\n",
    "# Second model VERY similar to first. It makes sense since we haven't made any big changes.\n",
    "# Today we make those big changes. Let's figure out the columns to drop based on p-values.\n",
    "# At the end I added my log code with some notes.\n",
    "\n",
    "# I see the light at the end of the tunnel. We'll get there!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "df = pd.read_csv('kc_house_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move price column to end. Helps with formula creation (data.columns[:-1] is the easiest solution I could find to not including price~price in formula)\n",
    "\n",
    "df = df[[c for c in df if c not in ['price']] + ['price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'date' and 'sqft_basement' columns cause a problem with the model.summary() Don't know why. Further research needed.\n",
    "# id column is clearly not part of the model\n",
    "\n",
    "df = df.drop(['date','sqft_basement','id','yr_built'], axis=1)\n",
    "\n",
    "#Would views or year renovated impact the price unless it was extremely dated? And, there are only two years on the year renovated category, which is limiting. We're thinking not likely, so we're going to remove those columns.  Also, we'd like to explore a way to fill the nan waterfront values but have decided to remove the column for now but may come back to. So we removed these columns\n",
    "df=df.drop(columns=['yr_renovated', 'view','waterfront','sqft_lot15','sqft_lot15'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(len(df[df.duplicated()]))\n",
    "df = df.drop_duplicates()\n",
    "print(df.isnull().sum().sum())\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df['sqft_basement'] = pd.to_numeric(df['sqft_basement'], errors='coerce')\n",
    "# print(df['sqft_basement'].isna().sum())\n",
    "# df = df.dropna()\n",
    "# print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist('price', bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['price'] = np.log(data['price'])\n",
    "data.hist('price', bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing outliers!\n",
    "# Step 1: Keep all homes with sale prices within 2 standard deviations of the mean.\n",
    "\n",
    "std = data['price'].std()\n",
    "mean = data['price'].mean()\n",
    "data = data[(data['price'] >= (mean - (2 * std))) & (data['price'] <= (mean + (2 * std)))]\n",
    "\n",
    "# Step 2: Split df into continuous and categorical values.\n",
    "\n",
    "dfcontin = data[['sqft_living', 'sqft_lot', 'sqft_above']]\n",
    "dfcat = data[['bedrooms', 'bathrooms', 'floors',\n",
    "       'condition', 'grade', 'zipcode', 'lat',\n",
    "       'long', 'price']]\n",
    "\n",
    "# Step 3: Removing homes with outliers for all remaining continuous values.\n",
    "# Obstacle was not wanting to run a for loop. A for loop would eliminate homes on each pass, leaving a smaller and smaller dataset with each pass, shrinking our data considerably.\n",
    "# Found stats.zscore. Very useful. Wish I used that in the first place.\n",
    "# 2 standard deviations eliminated too many homes. 2.5 seemed to be the sweet spot.\n",
    "\n",
    "dfcontin = dfcontin[(np.abs(stats.zscore(data)) < 2.5).all(axis=1)]\n",
    "data = dfcontin.merge(dfcat, left_index=True, right_index=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist('price', bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remaining homes have prices between $82,000 and $1,040,000.\n",
    "\n",
    "print(data['price'].max())\n",
    "print(data['price'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple regression model #1\n",
    "\n",
    "formula = 'price ~ '+ '+'.join(data.columns[:-1])\n",
    "model = ols(formula=formula, data=data).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.graphics.qqplot(model.resid, dist=stats.norm, line='45', fit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split for linear regression.\n",
    "\n",
    "data2 = data.copy()\n",
    "data2['price'] = np.exp(data2['price'])\n",
    "y = data2[['price']]\n",
    "X = data2.drop(['price'], axis=1)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "y_hat_train = linreg.predict(X_train)\n",
    "y_hat_test = linreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare RMSE.\n",
    "\n",
    "\n",
    "train_mse = mean_squared_error(y_train, y_hat_train)\n",
    "test_mse = mean_squared_error(y_test, y_hat_test)\n",
    "print('Train Mean Squared Error:', train_mse)\n",
    "print('Test Mean Squared Error:', test_mse)\n",
    "\n",
    "print('Train Root Mean Squared Error:', train_mse**0.5)\n",
    "print('Test Root Mean Squared Error:', test_mse**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To help identify categorical columns\n",
    "\n",
    "for col in data.columns:\n",
    "    print(len(data[col].unique()), col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From eyeballing it.\n",
    "\n",
    "likelycategorical = ['bedrooms','bathrooms','floors','waterfront','view','condition','grade']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect histograms for normality and better identify categoricals\n",
    "\n",
    "data.hist(figsize=(18,20));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plots to visualize categorical values\n",
    "\n",
    "fig, axes = plt.subplots(nrows=6, ncols=3, figsize=(16,15), sharey=True)\n",
    "\n",
    "for ax, column in zip(axes.flatten(), data.columns):\n",
    "    ax.scatter(data[column], data['price']/100_000, label=column, alpha=.1)\n",
    "    ax.set_title(f'Price vs {column}')\n",
    "    ax.set_xlabel(column)  \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sqft_living appears to be normally distributed.  And it looks promising with just a few outliers that we can clean up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap to visualize correlation\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "df_corr = data.corr()\n",
    "ax = sns.heatmap(df_corr, annot=True)\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 1, top -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sqft above and sqft liv are highly correlated.  Since the sqft living appears to fit the baseline model better with fewer outliers, we will select it as our feature for our next iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop column that was strongly correlated to another feature\n",
    "\n",
    "data.drop(columns=['sqft_above'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables for categorical values.\n",
    "\n",
    "floo_dummies = pd.get_dummies(data['floors'],prefix='floo',drop_first=True)\n",
    "bath_dummies = pd.get_dummies(data['bathrooms'], prefix='bath',drop_first=True)\n",
    "cond_dummies = pd.get_dummies(data['condition'], prefix='cond',drop_first=True)\n",
    "grad_dummies = pd.get_dummies(data['grade'], prefix='grad',drop_first=True)\n",
    "bed_dummies = pd.get_dummies(data['bedrooms'], prefix='bed',drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate. Behold our labor!\n",
    "# Make a second DataFrame, bedxbath, preserving bed and bath columns. To be used later.\n",
    "\n",
    "bedxbath = pd.concat([data, cond_dummies, grad_dummies ,floo_dummies], axis=1)\n",
    "data = pd.concat([data,bed_dummies,bath_dummies, cond_dummies, grad_dummies, floo_dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop original columns to make room for dummies.\n",
    "\n",
    "data.drop(['floors','bedrooms','bathrooms', 'condition', 'grade'],axis=1, inplace=True)\n",
    "\n",
    "bedxbath.drop(['floors','condition','grade'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once again, send price column to the end.\n",
    "\n",
    "data = data[[c for c in data if c not in ['price']] + ['price']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discovered statsmodels is particular about symbols in column names. The '.' in our dummy variables such as 'bed_1.5' threw an error in our ols model.\n",
    "# Solution: Create dictionary of {old_names : new_names} to use to rename columns.\n",
    "\n",
    "cleankeys = list(data.columns)\n",
    "cleanvalues = []\n",
    "for c in data.columns:\n",
    "    c = c.replace('.','_')\n",
    "    cleanvalues.append(c)\n",
    "    data\n",
    "cleancols = dict(zip(cleankeys, cleanvalues))\n",
    "data.rename(columns=cleancols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ols works now with the new column names. \n",
    "# Inspect our second model.\n",
    "\n",
    "formula = 'price ~ '+ ' + '.join(data.columns[:-1])\n",
    "model = ols(formula=formula, data=data).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop high p values\n",
    "\n",
    "data.drop(['sqft_lot','sqft_above'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.graphics.qqplot(model.resid, dist=stats.norm, line='45', fit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure it looks right before we continue.\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split for linear regression. Second round\n",
    "\n",
    "data2 = data.copy()\n",
    "y = data2[['price']]\n",
    "X = data2.drop(['price'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "y_hat_train = linreg.predict(X_train)\n",
    "y_hat_test = linreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare our new RMSE again.\n",
    "\n",
    "train_mse = mean_squared_error(y_train, y_hat_train)\n",
    "test_mse = mean_squared_error(y_test, y_hat_test)\n",
    "print('Train Mean Squared Error:', train_mse)\n",
    "print('Test Mean Squared Error:', test_mse)\n",
    "\n",
    "print('Train Root Mean Squared Error:', train_mse**0.5)\n",
    "print('Test Root Mean Squared Error:', test_mse**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very similar results. Time to start making more significant changes to see change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['price']\n",
    "cols = list(data.columns)\n",
    "cols.remove('price')\n",
    "pmax = 1\n",
    "X = data[cols]\n",
    "highpvalue = []\n",
    "while (len(cols)>0):\n",
    "    p= []\n",
    "    X_1 = X[cols]\n",
    "    X_1 = sm.add_constant(X_1)\n",
    "    model = sm.OLS(y,X_1).fit()\n",
    "    p = pd.Series(model.pvalues.values[1:],index = cols)      \n",
    "    pmax = max(p)\n",
    "    feature_with_p_max = p.idxmax()\n",
    "    if(pmax>0.05):\n",
    "        cols.remove(feature_with_p_max)\n",
    "        highpvalue.append(feature_with_p_max)\n",
    "    else:\n",
    "        break\n",
    "selected_features_BE = cols\n",
    "print(selected_features_BE)\n",
    "print(highpvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still have a ton of variables at play. Inspired by Amber Yandow's lesson, decided to get rid of bed and bath dummy variables and process them in a different way.\n",
    "# This is where earlier DataFrame named bedxbath comes into play.\n",
    "# Creating new column, bedxbath, where # of bedrooms are multiplied by # of baths. Drop bed and bath columns.\n",
    "\n",
    "bedxbath['bedxbath'] = bedxbath['bedrooms'] * bedxbath['bathrooms']\n",
    "bedxbath.drop(['bedrooms','bathrooms','sqft_above','sqft_lot'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedxbath['bedxbath'].hist()\n",
    "plt.show()\n",
    "logtest = pd.DataFrame()\n",
    "logtest['bedbathlog'] = np.log(bedxbath['bedxbath'])\n",
    "logtest.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleankeys = list(bedxbath.columns)\n",
    "cleanvalues = []\n",
    "for c in bedxbath.columns:\n",
    "    c = c.replace('.','_')\n",
    "    cleanvalues.append(c)\n",
    "    data\n",
    "cleancols = dict(zip(cleankeys, cleanvalues))\n",
    "bedxbath.rename(columns=cleancols, inplace=True)\n",
    "\n",
    "bedxbath = bedxbath[[c for c in bedxbath if c not in ['price']] + ['price']]\n",
    "\n",
    "formula = 'price ~ '+ '+'.join(bedxbath.columns[:-1])\n",
    "model = ols(formula=formula, data=bedxbath).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.graphics.qqplot(model.resid, dist=stats.norm, line='45', fit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bedxbath.drop(['bedxbath'], axis=1, inplace=True)\n",
    "bedxbath['bedbathlog'] = logtest['bedbathlog']\n",
    "\n",
    "cleankeys = list(bedxbath.columns)\n",
    "cleanvalues = []\n",
    "for c in bedxbath.columns:\n",
    "    c = c.replace('.','_')\n",
    "    cleanvalues.append(c)\n",
    "    data\n",
    "cleancols = dict(zip(cleankeys, cleanvalues))\n",
    "bedxbath.rename(columns=cleancols, inplace=True)\n",
    "\n",
    "bedxbath = bedxbath[[c for c in bedxbath if c not in ['price']] + ['price']]\n",
    "\n",
    "formula = 'price ~ '+ '+'.join(bedxbath.columns[:-1])\n",
    "model = ols(formula=formula, data=bedxbath).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_corr = ((abs(bedxbath.corr())> .8).sum()>1)\n",
    "print(high_corr)\n",
    "bedxbath.drop(['cond_3','cond_4'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'price ~ '+ '+'.join(bedxbath.columns[:-1])\n",
    "model = ols(formula=formula, data=bedxbath).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in bedxbath.columns:\n",
    "    formula= f'price ~ + {column}'\n",
    "    model = ols(formula=formula, data=bedxbath).fit()\n",
    "    print(column)\n",
    "    sm.graphics.qqplot(model.resid, dist=stats.norm, line='45', fit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized = pd.DataFrame()\n",
    "def scale(col):\n",
    "    return(bedxbath[col] - bedxbath[col].mean()) / bedxbath[col].std()\n",
    "price = pd.DataFrame()\n",
    "price['logprice'] = data['price']\n",
    "bedxbath.drop('price',axis=1)\n",
    "for col in bedxbath.columns:\n",
    "    standardized[col] = scale(col)\n",
    "standardized = pd.concat([standardized, price], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized.drop('price', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formula = 'logprice ~ '+ '+'.join(standardized.columns[:-1])\n",
    "model = ols(formula=formula, data=standardized).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized.drop('floo_2_0', axis=1, inplace=True)\n",
    "formula = 'logprice ~ '+ '+'.join(standardized.columns[:-1])\n",
    "model = ols(formula=formula, data=standardized).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split for linear regression.\n",
    "\n",
    "standardized2 = standardized.copy()\n",
    "standardized2['logprice'] = np.exp(standardized2['logprice'])\n",
    "y = standardized2[['logprice']]\n",
    "X = standardized2.drop(['logprice'], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "y_hat_train = linreg.predict(X_train)\n",
    "y_hat_test = linreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare RMSE.\n",
    "\n",
    "train_mse = mean_squared_error(y_train, y_hat_train)\n",
    "test_mse = mean_squared_error(y_test, y_hat_test)\n",
    "print('Train Mean Squared Error:', train_mse)\n",
    "print('Test Mean Squared Error:', test_mse)\n",
    "\n",
    "print('Train Root Mean Squared Error:', train_mse**0.5)\n",
    "print('Test Root Mean Squared Error:', test_mse**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### THIS IS HERE TO WORK WITH TOMORROW\n",
    "# Logs for some variables.\n",
    "\n",
    "data_log = pd.DataFrame([])\n",
    "data_log['log_living'] = np.log(data['sqft_living'])\n",
    "\n",
    "logs = ['sqft_living']\n",
    "\n",
    "data_log.hist(figsize= [6,6])\n",
    "data[logs].hist(figsize= [6,6]);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For comparison, same variables without the log.\n",
    "# Large improvement in 'sqft_lot' and 'sqft_lot15'.\n",
    "# Medium improvement in 'sqft_above'\n",
    "\n",
    "\n",
    "data[logs].hist(figsize= [6,6]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testlogs = pd.concat([data_log, data[logs], data['price']], axis=1)\n",
    "\n",
    "formula = 'price ~ '+ '+'.join(testlogs.columns[:-1])\n",
    "model = ols(formula=formula, data=testlogs).fit()\n",
    "print(model.summary())\n",
    "print(testlogs.columns[:-1], model.pvalues.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Hi Tim!  I'm starting my convo here.  Also, I've added some comments throughout as Yish mention in the project documentation\n",
    "# #to include questions and thoughts about our decisions throughout the notebook, #so trying to check off all the asks on the list\n",
    "# #Here is a linear regression model we can use as our baseline.  It's not in the right spot, but we can figure that out after we\n",
    "# #clean up the notebook a bit.  It needs to go after the train-test-split\n",
    "\n",
    "# import statsmodels.api as sm\n",
    "# import statsmodels.formula.api as smf\n",
    "# import scipy.stats as stats\n",
    "# import statsmodels.stats.api as sms\n",
    "\n",
    "# results = []\n",
    "# for idx, column in enumerate(data.columns):\n",
    "#     print (f\"SeattleHousingData - Regression Analysis and Diagnostics for price~{column}\")\n",
    "#     print (\"--------------------------------------------------------------------------------------\")\n",
    "    \n",
    "#     f = f'price~{column}'\n",
    "#     model = smf.ols(formula=f, data=data).fit()\n",
    "    \n",
    "  \n",
    "#     fig, axes = plt.subplots(figsize=(15,12))\n",
    "#     fig = sm.graphics.plot_regress_exog(model, column, fig=fig)\n",
    "#     fig = sm.graphics.qqplot(model.resid, dist=stats.norm, line='45', fit=True)\n",
    "#     fig.tight_layout()\n",
    "#     plt.show()\n",
    "    \n",
    "#     results.append([column, model.rsquared, model.params[0], model.params[1], model.pvalues[1], sms.jarque_bera(model.resid)[0]])\n",
    "#     input(\"Press Enter to continue...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.pvalues.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['zipcode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=6, ncols=3, figsize=(16,15), sharey=True)\n",
    "for ax, column in zip(axes.flatten(), df.columns):\n",
    "    ax.scatter(df[column], df['price']/100_000, label=column, alpha=.1)\n",
    "    ax.set_title(f'Price vs {column}')\n",
    "    ax.set_xlabel(column)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}